{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd3030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ✅ STEP 1: Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# ✅ STEP 2: Install Hugging Face datasets\n",
    "!pip install datasets -q\n",
    "\n",
    "# ✅ STEP 3: Create folders in Drive\n",
    "import os\n",
    "\n",
    "base_path = \"/content/drive/MyDrive/AI_Reasoning_Datasets\"\n",
    "os.makedirs(base_path, exist_ok=True)\n",
    "\n",
    "# ✅ STEP 4: Load and Save GSM8K Dataset\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "\n",
    "gsm8k = load_dataset(\"gsm8k\", \"main\")\n",
    "gsm8k_path = f\"{base_path}/gsm8k_sample.json\"\n",
    "with open(gsm8k_path, \"w\") as f:\n",
    "    json.dump(gsm8k[\"train\"][:100], f)\n",
    "print(f\"GSM8K sample saved to: {gsm8k_path}\")\n",
    "\n",
    "# ✅ STEP 5: Load and Save MATH Dataset\n",
    "math_ds = load_dataset(\"openai/math\", \"algebra\")\n",
    "math_path = f\"{base_path}/math_sample.json\"\n",
    "with open(math_path, \"w\") as f:\n",
    "    json.dump(math_ds[\"test\"][:100], f)\n",
    "print(f\"MATH dataset sample saved to: {math_path}\")\n",
    "\n",
    "# ✅ STEP 6: Clone ARC and copy to Drive\n",
    "!git clone https://github.com/fchollet/ARC.git\n",
    "!cp -r ARC/data {base_path}/ARC_data\n",
    "print(\"ARC data copied to Drive.\")\n",
    "\n",
    "# ✅ STEP 7: Load and Save Lean Dojo Dataset\n",
    "lean = load_dataset(\"lean-dojo/benchmarks\", split=\"train\")\n",
    "lean_path = f\"{base_path}/lean_dojo_sample.json\"\n",
    "with open(lean_path, \"w\") as f:\n",
    "    json.dump(lean[:100], f)\n",
    "print(f\"Lean Dojo sample saved to: {lean_path}\")\n",
    "\n",
    "# ✅ STEP 8: Load and Save HumanEval\n",
    "humaneval = load_dataset(\"openai_humaneval\")\n",
    "he_path = f\"{base_path}/humaneval_sample.json\"\n",
    "with open(he_path, \"w\") as f:\n",
    "    json.dump(humaneval[\"test\"][:100], f)\n",
    "print(f\"HumanEval sample saved to: {he_path}\")\n",
    "\n",
    "# ✅ STEP 9: Load and Save MBPP\n",
    "mbpp = load_dataset(\"mbpp\")\n",
    "mbpp_path = f\"{base_path}/mbpp_sample.json\"\n",
    "with open(mbpp_path, \"w\") as f:\n",
    "    json.dump(mbpp[\"train\"][:100], f)\n",
    "print(f\"MBPP sample saved to: {mbpp_path}\")\n",
    "\n",
    "# ✅ STEP 10: Load and Save Code Instructions\n",
    "code_instruct = load_dataset(\"codeparrot/code_instructions_filtered\")\n",
    "ci_path = f\"{base_path}/code_instruct_sample.json\"\n",
    "with open(ci_path, \"w\") as f:\n",
    "    json.dump(code_instruct[\"train\"][:100], f)\n",
    "print(f\"Code Instructions sample saved to: {ci_path}\")\n",
    "\n",
    "# ✅ STEP 11: Stream The Stack (Python) and Save\n",
    "stack = load_dataset(\"bigcode/the-stack\", data_dir=\"data/python\", split=\"train\", streaming=True)\n",
    "stack_samples = [x for _, x in zip(range(10), stack)]\n",
    "stack_path = f\"{base_path}/stack_python_sample.json\"\n",
    "with open(stack_path, \"w\") as f:\n",
    "    json.dump(stack_samples, f)\n",
    "print(f\"The Stack (Python) sample saved to: {stack_path}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}